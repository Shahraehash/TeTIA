{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Notebook for Generating Audios from Make-An-Audio 2 Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l3qUOJgqDXCb",
        "outputId": "e71f872d-f85a-4cdd-a7d5-a94bae5ea377"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/home/ec2-user/Make-An-Audio-2\n",
            "/home/ec2-user/Make-An-Audio-2\n"
          ]
        }
      ],
      "source": [
        "%cd Make-An-Audio-2\n",
        "!pwd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "P1v3xBPVEpen",
        "outputId": "20768458-cd71-4c24-cc78-7c20106be7b1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://download.pytorch.org/whl/cu113\n",
            "Obtaining BigVGAN from git+https://github.com/awei-6/BigVGAN.git@main#egg=BigVGAN (from -r requirements.txt (line 26))\n",
            "  Updating ./src/bigvgan clone (to revision main)\n",
            "  Running command git fetch -q --tags\n",
            "  Running command git reset --hard -q ac17a79ca9abe1a49a7c23f52f73d405fbd90da4\n",
            "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
            "\u001b[?25hCollecting torch==1.13.0\n",
            "  Downloading torch-1.13.0-cp39-cp39-manylinux1_x86_64.whl (890.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m890.2/890.2 MB\u001b[0m \u001b[31m958.8 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: torchaudio>=0.13.0 in /opt/conda/envs/pytorch/lib/python3.9/site-packages (from -r requirements.txt (line 4)) (0.13.1)\n",
            "Requirement already satisfied: torchvision>=0.14.0 in /opt/conda/envs/pytorch/lib/python3.9/site-packages (from -r requirements.txt (line 5)) (0.14.1)\n",
            "Collecting torch-fidelity\n",
            "  Downloading torch_fidelity-0.3.0-py3-none-any.whl (37 kB)\n",
            "Requirement already satisfied: scipy in /opt/conda/envs/pytorch/lib/python3.9/site-packages (from -r requirements.txt (line 7)) (1.11.1)\n",
            "Requirement already satisfied: importlib_resources in /opt/conda/envs/pytorch/lib/python3.9/site-packages (from -r requirements.txt (line 8)) (6.0.1)\n",
            "Collecting tensorboard\n",
            "  Downloading tensorboard-2.18.0-py3-none-any.whl (5.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.5/5.5 MB\u001b[0m \u001b[31m121.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm in /opt/conda/envs/pytorch/lib/python3.9/site-packages (from -r requirements.txt (line 10)) (4.63.2)\n",
            "Collecting omegaconf\n",
            "  Downloading omegaconf-2.3.0-py3-none-any.whl (79 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.5/79.5 kB\u001b[0m \u001b[31m31.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting einops\n",
            "  Downloading einops-0.8.0-py3-none-any.whl (43 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.2/43.2 kB\u001b[0m \u001b[31m15.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting soundfile\n",
            "  Downloading soundfile-0.12.1-py2.py3-none-manylinux_2_17_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m129.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting librosa\n",
            "  Downloading librosa-0.10.2.post1-py3-none-any.whl (260 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m260.1/260.1 kB\u001b[0m \u001b[31m69.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting scikit-image==0.19.3\n",
            "  Downloading scikit_image-0.19.3-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (14.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.0/14.0 MB\u001b[0m \u001b[31m117.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pandas in /opt/conda/envs/pytorch/lib/python3.9/site-packages (from -r requirements.txt (line 16)) (1.4.4)\n",
            "Collecting torchlibrosa\n",
            "  Downloading torchlibrosa-0.1.0-py3-none-any.whl (11 kB)\n",
            "Collecting transformers==4.26.0\n",
            "  Downloading transformers-4.26.0-py3-none-any.whl (6.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.3/6.3 MB\u001b[0m \u001b[31m128.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
            "\u001b[?25hCollecting safetensors\n",
            "  Downloading safetensors-0.4.5-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (436 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m436.1/436.1 kB\u001b[0m \u001b[31m86.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting ftfy\n",
            "  Downloading ftfy-6.3.1-py3-none-any.whl (44 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.8/44.8 kB\u001b[0m \u001b[31m12.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pytorch-lightning\n",
            "  Downloading pytorch_lightning-2.4.0-py3-none-any.whl (815 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m815.2/815.2 kB\u001b[0m \u001b[31m75.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting torchmetrics==0.11.1\n",
            "  Downloading torchmetrics-0.11.1-py3-none-any.whl (517 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m517.2/517.2 kB\u001b[0m \u001b[31m55.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting resampy\n",
            "  Downloading resampy-0.4.3-py3-none-any.whl (3.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m42.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
            "\u001b[?25hCollecting ssr_eval\n",
            "  Downloading ssr_eval-0.0.7-py3-none-any.whl (15 kB)\n",
            "Collecting nvidia-cuda-nvrtc-cu11==11.7.99\n",
            "  Downloading nvidia_cuda_nvrtc_cu11-11.7.99-2-py3-none-manylinux1_x86_64.whl (21.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.0/21.0 MB\u001b[0m \u001b[31m28.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: typing-extensions in /opt/conda/envs/pytorch/lib/python3.9/site-packages (from torch==1.13.0->-r requirements.txt (line 3)) (4.7.1)\n",
            "Collecting nvidia-cuda-runtime-cu11==11.7.99\n",
            "  Downloading nvidia_cuda_runtime_cu11-11.7.99-py3-none-manylinux1_x86_64.whl (849 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m849.3/849.3 kB\u001b[0m \u001b[31m23.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cublas-cu11==11.10.3.66\n",
            "  Downloading nvidia_cublas_cu11-11.10.3.66-py3-none-manylinux1_x86_64.whl (317.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m317.1/317.1 MB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cudnn-cu11==8.5.0.96\n",
            "  Downloading nvidia_cudnn_cu11-8.5.0.96-2-py3-none-manylinux1_x86_64.whl (557.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m557.1/557.1 MB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
            "\u001b[?25hCollecting PyWavelets>=1.1.1\n",
            "  Downloading pywavelets-1.6.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.5/4.5 MB\u001b[0m \u001b[31m126.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
            "\u001b[?25hCollecting networkx>=2.2\n",
            "  Downloading https://download.pytorch.org/whl/networkx-3.2.1-py3-none-any.whl (1.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m28.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m \u001b[36m0:00:01\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17.0 in /opt/conda/envs/pytorch/lib/python3.9/site-packages (from scikit-image==0.19.3->-r requirements.txt (line 15)) (1.24.4)\n",
            "Collecting tifffile>=2019.7.26\n",
            "  Downloading tifffile-2024.8.30-py3-none-any.whl (227 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m227.3/227.3 kB\u001b[0m \u001b[31m68.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: imageio>=2.4.1 in /opt/conda/envs/pytorch/lib/python3.9/site-packages (from scikit-image==0.19.3->-r requirements.txt (line 15)) (2.16.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /opt/conda/envs/pytorch/lib/python3.9/site-packages (from scikit-image==0.19.3->-r requirements.txt (line 15)) (21.3)\n",
            "Requirement already satisfied: pillow!=7.1.0,!=7.1.1,!=8.3.0,>=6.1.0 in /opt/conda/envs/pytorch/lib/python3.9/site-packages (from scikit-image==0.19.3->-r requirements.txt (line 15)) (10.0.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/envs/pytorch/lib/python3.9/site-packages (from transformers==4.26.0->-r requirements.txt (line 18)) (6.0)\n",
            "Collecting regex!=2019.12.17\n",
            "  Downloading regex-2024.11.6-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (780 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m780.9/780.9 kB\u001b[0m \u001b[31m101.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tokenizers!=0.11.3,<0.14,>=0.11.1\n",
            "  Downloading tokenizers-0.13.3-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m99.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /opt/conda/envs/pytorch/lib/python3.9/site-packages (from transformers==4.26.0->-r requirements.txt (line 18)) (3.6.0)\n",
            "Requirement already satisfied: requests in /opt/conda/envs/pytorch/lib/python3.9/site-packages (from transformers==4.26.0->-r requirements.txt (line 18)) (2.31.0)\n",
            "Collecting huggingface-hub<1.0,>=0.11.0\n",
            "  Downloading huggingface_hub-0.26.5-py3-none-any.whl (447 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m447.8/447.8 kB\u001b[0m \u001b[31m14.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: setuptools in /opt/conda/envs/pytorch/lib/python3.9/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch==1.13.0->-r requirements.txt (line 3)) (68.0.0)\n",
            "Requirement already satisfied: wheel in /opt/conda/envs/pytorch/lib/python3.9/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch==1.13.0->-r requirements.txt (line 3)) (0.41.1)\n",
            "Requirement already satisfied: zipp>=3.1.0 in /opt/conda/envs/pytorch/lib/python3.9/site-packages (from importlib_resources->-r requirements.txt (line 8)) (3.16.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /opt/conda/envs/pytorch/lib/python3.9/site-packages (from tensorboard->-r requirements.txt (line 9)) (2.3.7)\n",
            "Collecting grpcio>=1.48.2\n",
            "  Downloading grpcio-1.68.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.9/5.9 MB\u001b[0m \u001b[31m48.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
            "\u001b[?25hCollecting tensorboard-data-server<0.8.0,>=0.7.0\n",
            "  Downloading tensorboard_data_server-0.7.2-py3-none-any.whl (2.4 kB)\n",
            "Collecting absl-py>=0.4\n",
            "  Downloading absl_py-2.1.0-py3-none-any.whl (133 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m133.7/133.7 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting markdown>=2.6.8\n",
            "  Downloading Markdown-3.7-py3-none-any.whl (106 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m106.3/106.3 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: protobuf!=4.24.0,>=3.19.6 in /opt/conda/envs/pytorch/lib/python3.9/site-packages (from tensorboard->-r requirements.txt (line 9)) (3.20.2)\n",
            "Requirement already satisfied: six>1.9 in /opt/conda/envs/pytorch/lib/python3.9/site-packages (from tensorboard->-r requirements.txt (line 9)) (1.16.0)\n",
            "Collecting antlr4-python3-runtime==4.9.*\n",
            "  Downloading antlr4-python3-runtime-4.9.3.tar.gz (117 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m117.0/117.0 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
            "\u001b[?25hRequirement already satisfied: cffi>=1.0 in /opt/conda/envs/pytorch/lib/python3.9/site-packages (from soundfile->-r requirements.txt (line 13)) (1.15.1)\n",
            "Collecting msgpack>=1.0\n",
            "  Downloading msgpack-1.1.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (377 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m377.9/377.9 kB\u001b[0m \u001b[31m10.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: decorator>=4.3.0 in /opt/conda/envs/pytorch/lib/python3.9/site-packages (from librosa->-r requirements.txt (line 14)) (5.1.1)\n",
            "Requirement already satisfied: numba>=0.51.0 in /opt/conda/envs/pytorch/lib/python3.9/site-packages (from librosa->-r requirements.txt (line 14)) (0.57.1)\n",
            "Collecting audioread>=2.1.9\n",
            "  Downloading audioread-3.0.1-py3-none-any.whl (23 kB)\n",
            "Collecting soxr>=0.3.2\n",
            "  Downloading soxr-0.5.0.post1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (253 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m253.0/253.0 kB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting lazy-loader>=0.1\n",
            "  Downloading lazy_loader-0.4-py3-none-any.whl (12 kB)\n",
            "Requirement already satisfied: pooch>=1.1 in /opt/conda/envs/pytorch/lib/python3.9/site-packages (from librosa->-r requirements.txt (line 14)) (1.7.0)\n",
            "Requirement already satisfied: scikit-learn>=0.20.0 in /opt/conda/envs/pytorch/lib/python3.9/site-packages (from librosa->-r requirements.txt (line 14)) (1.0)\n",
            "Requirement already satisfied: joblib>=0.14 in /opt/conda/envs/pytorch/lib/python3.9/site-packages (from librosa->-r requirements.txt (line 14)) (1.3.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /opt/conda/envs/pytorch/lib/python3.9/site-packages (from pandas->-r requirements.txt (line 16)) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /opt/conda/envs/pytorch/lib/python3.9/site-packages (from pandas->-r requirements.txt (line 16)) (2023.3)\n",
            "Requirement already satisfied: wcwidth in /opt/conda/envs/pytorch/lib/python3.9/site-packages (from ftfy->-r requirements.txt (line 20)) (0.2.6)\n",
            "Collecting lightning-utilities>=0.10.0\n",
            "  Downloading lightning_utilities-0.11.9-py3-none-any.whl (28 kB)\n",
            "Collecting pytorch-lightning\n",
            "  Downloading pytorch_lightning-2.3.3-py3-none-any.whl (812 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m812.3/812.3 kB\u001b[0m \u001b[31m20.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
            "\u001b[?25h  Downloading pytorch_lightning-2.3.2-py3-none-any.whl (812 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m812.3/812.3 kB\u001b[0m \u001b[31m19.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
            "\u001b[?25h  Downloading pytorch_lightning-2.3.1-py3-none-any.whl (812 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m812.3/812.3 kB\u001b[0m \u001b[31m18.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
            "\u001b[?25h  Downloading pytorch_lightning-2.3.0-py3-none-any.whl (812 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m812.2/812.2 kB\u001b[0m \u001b[31m19.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
            "\u001b[?25h  Downloading pytorch_lightning-2.2.5-py3-none-any.whl (802 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m802.3/802.3 kB\u001b[0m \u001b[31m18.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: fsspec[http]>=2022.5.0 in /opt/conda/envs/pytorch/lib/python3.9/site-packages (from pytorch-lightning->-r requirements.txt (line 21)) (2023.6.0)\n",
            "Collecting wave\n",
            "  Downloading Wave-0.0.2.zip (38 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
            "\u001b[?25hCollecting pesq\n",
            "  Downloading pesq-0.0.4.tar.gz (38 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
            "\u001b[?25hCollecting auraloss\n",
            "  Downloading auraloss-0.4.0-py3-none-any.whl (16 kB)\n",
            "Requirement already satisfied: pycparser in /opt/conda/envs/pytorch/lib/python3.9/site-packages (from cffi>=1.0->soundfile->-r requirements.txt (line 13)) (2.21)\n",
            "Collecting aiohttp!=4.0.0a0,!=4.0.0a1\n",
            "  Downloading aiohttp-3.11.10-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m137.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: importlib-metadata>=4.4 in /opt/conda/envs/pytorch/lib/python3.9/site-packages (from markdown>=2.6.8->tensorboard->-r requirements.txt (line 9)) (6.8.0)\n",
            "Requirement already satisfied: llvmlite<0.41,>=0.40.0dev0 in /opt/conda/envs/pytorch/lib/python3.9/site-packages (from numba>=0.51.0->librosa->-r requirements.txt (line 14)) (0.40.1)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/envs/pytorch/lib/python3.9/site-packages (from packaging>=20.0->scikit-image==0.19.3->-r requirements.txt (line 15)) (3.1.1)\n",
            "Requirement already satisfied: platformdirs>=2.5.0 in /opt/conda/envs/pytorch/lib/python3.9/site-packages (from pooch>=1.1->librosa->-r requirements.txt (line 14)) (3.10.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/envs/pytorch/lib/python3.9/site-packages (from requests->transformers==4.26.0->-r requirements.txt (line 18)) (2023.7.22)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/envs/pytorch/lib/python3.9/site-packages (from requests->transformers==4.26.0->-r requirements.txt (line 18)) (1.26.15)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/envs/pytorch/lib/python3.9/site-packages (from requests->transformers==4.26.0->-r requirements.txt (line 18)) (3.4)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/envs/pytorch/lib/python3.9/site-packages (from requests->transformers==4.26.0->-r requirements.txt (line 18)) (3.2.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/envs/pytorch/lib/python3.9/site-packages (from scikit-learn>=0.20.0->librosa->-r requirements.txt (line 14)) (3.2.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /opt/conda/envs/pytorch/lib/python3.9/site-packages (from werkzeug>=1.0.1->tensorboard->-r requirements.txt (line 9)) (2.1.3)\n",
            "Collecting multidict<7.0,>=4.5\n",
            "  Downloading multidict-6.1.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (124 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.1/124.1 kB\u001b[0m \u001b[31m31.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting frozenlist>=1.1.1\n",
            "  Downloading frozenlist-1.5.0-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (242 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m242.9/242.9 kB\u001b[0m \u001b[31m67.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: attrs>=17.3.0 in /opt/conda/envs/pytorch/lib/python3.9/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning->-r requirements.txt (line 21)) (23.1.0)\n",
            "Collecting yarl<2.0,>=1.17.0\n",
            "  Downloading yarl-1.18.3-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (321 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m321.5/321.5 kB\u001b[0m \u001b[31m81.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting aiosignal>=1.1.2\n",
            "  Downloading aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
            "Collecting propcache>=0.2.0\n",
            "  Downloading propcache-0.2.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (208 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m208.3/208.3 kB\u001b[0m \u001b[31m53.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting async-timeout<6.0,>=4.0\n",
            "  Downloading async_timeout-5.0.1-py3-none-any.whl (6.2 kB)\n",
            "Collecting aiohappyeyeballs>=2.3.0\n",
            "  Downloading aiohappyeyeballs-2.4.4-py3-none-any.whl (14 kB)\n",
            "Building wheels for collected packages: antlr4-python3-runtime, pesq, wave\n",
            "  Building wheel for antlr4-python3-runtime (setup.py) ... \u001b[?25ldone\n",
            "\u001b[?25h  Created wheel for antlr4-python3-runtime: filename=antlr4_python3_runtime-4.9.3-py3-none-any.whl size=144555 sha256=a50a1695d98b68c4b5d59d1f0a4dcee5a79edc3e04f1596021e9ac8422adf65d\n",
            "  Stored in directory: /home/ec2-user/.cache/pip/wheels/a7/72/3e/7d4bb4df2f34e8a15d0d764bb98e7ca19a765483710646a8b3\n",
            "  Building wheel for pesq (setup.py) ... \u001b[?25ldone\n",
            "\u001b[?25h  Created wheel for pesq: filename=pesq-0.0.4-cp39-cp39-linux_x86_64.whl size=117367 sha256=6616c54f1952019050517a1eeb65c437f152bf4f46b996c77dc847ca25ce7b7e\n",
            "  Stored in directory: /home/ec2-user/.cache/pip/wheels/4f/96/fc/dffb5980f04ca15850cc1bb9a4c8ee08ab02a5e2c53a48ec4f\n",
            "  Building wheel for wave (setup.py) ... \u001b[?25ldone\n",
            "\u001b[?25h  Created wheel for wave: filename=Wave-0.0.2-py3-none-any.whl size=1220 sha256=c172d5a651ac7652aa37c8060910f23bf145be93ffaeff9d4ad263b25a938e11\n",
            "  Stored in directory: /home/ec2-user/.cache/pip/wheels/21/14/56/8169efc7eb39c24512522be522a18fdf81adbd6d40c8fd5a5c\n",
            "Successfully built antlr4-python3-runtime pesq wave\n",
            "Installing collected packages: wave, tokenizers, pesq, antlr4-python3-runtime, tifffile, tensorboard-data-server, soxr, safetensors, regex, PyWavelets, propcache, omegaconf, nvidia-cuda-runtime-cu11, nvidia-cuda-nvrtc-cu11, nvidia-cublas-cu11, networkx, multidict, msgpack, grpcio, ftfy, frozenlist, einops, audioread, async-timeout, aiohappyeyeballs, absl-py, yarl, soundfile, scikit-image, resampy, nvidia-cudnn-cu11, markdown, lightning-utilities, lazy-loader, huggingface-hub, aiosignal, transformers, torch, tensorboard, librosa, aiohttp, torchmetrics, torchlibrosa, auraloss, torch-fidelity, ssr_eval, pytorch-lightning, BigVGAN\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 1.13.1\n",
            "    Uninstalling torch-1.13.1:\n",
            "      Successfully uninstalled torch-1.13.1\n",
            "  Running setup.py develop for BigVGAN\n",
            "Successfully installed BigVGAN-0.1 PyWavelets-1.6.0 absl-py-2.1.0 aiohappyeyeballs-2.4.4 aiohttp-3.11.10 aiosignal-1.3.1 antlr4-python3-runtime-4.9.3 async-timeout-5.0.1 audioread-3.0.1 auraloss-0.4.0 einops-0.8.0 frozenlist-1.5.0 ftfy-6.3.1 grpcio-1.68.1 huggingface-hub-0.26.5 lazy-loader-0.4 librosa-0.10.2.post1 lightning-utilities-0.11.9 markdown-3.7 msgpack-1.1.0 multidict-6.1.0 networkx-3.2.1 nvidia-cublas-cu11-11.10.3.66 nvidia-cuda-nvrtc-cu11-11.7.99 nvidia-cuda-runtime-cu11-11.7.99 nvidia-cudnn-cu11-8.5.0.96 omegaconf-2.3.0 pesq-0.0.4 propcache-0.2.1 pytorch-lightning-2.2.5 regex-2024.11.6 resampy-0.4.3 safetensors-0.4.5 scikit-image-0.19.3 soundfile-0.12.1 soxr-0.5.0.post1 ssr_eval-0.0.7 tensorboard-2.18.0 tensorboard-data-server-0.7.2 tifffile-2024.8.30 tokenizers-0.13.3 torch-1.13.0 torch-fidelity-0.3.0 torchlibrosa-0.1.0 torchmetrics-0.11.1 transformers-4.26.0 wave-0.0.2 yarl-1.18.3\n"
          ]
        }
      ],
      "source": [
        "!pip install -r requirements.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/opt/conda/envs/pytorch/lib/python3.9/site-packages/huggingface_hub/file_download.py:797: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "200it [00:07, 25.60it/s]\n",
            "clap_score for maa1_ft.tsv is:0.602058470249176\n",
            "clap_score for maa1_ft.tsv is:0.602058470249176\n",
            "clap_score for maa1_ft.tsv is:0.602058470249176\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "# Used to calculated CLAP scores\n",
        "!python -m wav_evaluation.cal_clap_score --csv_path maa1_ft.tsv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "dWXtLGMy5dwb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "3it [00:00, 62291.64it/s]\n",
            "100%|█████████████████████████████████████████████| 3/3 [00:00<00:00, 28.16it/s]\n",
            "[]\n",
            "3it [00:00, 81180.08it/s]\n",
            "/opt/conda/envs/pytorch/lib/python3.9/site-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 16 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "100%|█████████████████████████████████████████████| 3/3 [00:02<00:00,  1.11it/s]\n",
            "proceoss mel done\n",
            "done\n"
          ]
        }
      ],
      "source": [
        "# Used to produce spectrograms\n",
        "!python -m preprocess.mel_spec --tsv_path make_spec.tsv --num_gpus 1 --max_duration 10"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tNhuoRz501OQ"
      },
      "outputs": [],
      "source": [
        "# Used to produce GPT-3.5 structured captions\n",
        "!python preprocess/n2s_by_openai.py --tsv_path maa2.tsv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# This block is to generate audios from captions in test_df.csv\n",
        "\n",
        "import pandas as pd\n",
        "import subprocess \n",
        "\n",
        "df = pd.read_csv('test_df.csv')\n",
        "for _, row in df.iterrows():\n",
        "    name = row['Audio_mp3'][:-4]\n",
        "    cap = row['Caption']\n",
        "    str_cap = row['Structured_Caption']\n",
        "\n",
        "    command = f\"python -m scripts.gen_wav --scale 4  --duration 10 --save_name gen_wav/{name} --prompt \\\"{cap}\\\" --struct_prompt \\\"{str_cap}\\\"\"\n",
        "    result = subprocess.run(command, shell=True, capture_output=True, text=True)\n",
        "    print(result.stderr)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2ZHx3qHEcVGR",
        "outputId": "1c4a3e7f-47ba-4278-dfc1-e1443c35c167"
      },
      "outputs": [],
      "source": [
        "# This block is to finish off generating captions (I had to stop halfway since I ran out of colab time. I saved the files I'd already generated in progress.pkl)\n",
        "\n",
        "import pandas as pd\n",
        "import subprocess\n",
        "import pickle\n",
        "\n",
        "file_path = 'progress.pkl'\n",
        "\n",
        "# Open the pickle file in read-binary mode and load the dictionary\n",
        "with open(file_path, 'rb') as file:\n",
        "    comp = pickle.load(file)\n",
        "\n",
        "df = pd.read_csv('maa2_struct.tsv', delimiter='\\t')\n",
        "for _, row in df.iterrows():\n",
        "    name = row['name'][:-4]\n",
        "    if name in comp:\n",
        "        continue\n",
        "    cap = row['caption']\n",
        "    str_cap = row['struct_cap']\n",
        "\n",
        "    command = f\"python -m scripts.gen_wav --scale 4  --duration 10 --save_name gen_wav/{name} --prompt \\\"{cap}\\\" --struct_prompt \\\"{str_cap}\\\"\"\n",
        "    result = subprocess.run(command, shell=True, capture_output=True, text=True)\n",
        "    print(result.stderr)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "pytorch",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.17"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
